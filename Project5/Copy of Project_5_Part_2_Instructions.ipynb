{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Project_5_Part_2_Instructions.ipynb","provenance":[{"file_id":"1uStmRjtLrofyELRzbJNJKvDZoqwCifg2","timestamp":1583958111516},{"file_id":"1znPlrqSMftHrm2k9HhnkievFaLqzFAM1","timestamp":1582914043162}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"e4VWMuMMy3Zc","colab_type":"text"},"source":["# Project 5: Vision (Part 2)\n","\n","Due Date: Monday, March 23, 2020 @ 11:59 P.M.\n","\n","Student #1 Name: Fei Ding\n","\n","Student #2 Name: Zhen Jiang\n","\n","Student #3 Name: Francis Kim\n","\n","Student #4 Name: Eric Yan\n","\n","In this part of project 5, you will be using the images you captured during part 1 to compute the change in orientation as the duckiebot moves along the road.  "]},{"cell_type":"markdown","metadata":{"id":"woz68IlozlQq","colab_type":"text"},"source":["##1. SETUP\n","\n","We are assuming that project 5 part 1 was successfully completed and:\n","\n","a) You have your 20+ images saved in a google drive folder.\n","\n","b) You have recorded ground truth for the robot's final pose.\n","\n","For this part of project 5, you will continue to work in the 4-person groups from part 1. Starting today, we will not allow further team switching. Please let us know if your partner team has been unresponsive. Below is the link to the sheet listing team pairs for reference:\n","\n","https://drive.google.com/file/d/1sS5btopwpchRhY5tD6-70TqP8LkjjpSg/view?usp=sharing\n","\n","In the code below, fill in all of the sections marked TODO.\n","\n","There are unit tests to test each of the students functions that they fill as well."]},{"cell_type":"markdown","metadata":{"id":"WtSzN_b22DcF","colab_type":"text"},"source":["##Reference Material to help write the code\n","\n","###Goal of this project\n","In this project, you will be using the images of the road and lanes captured while the duckiebot was driving, to figure out the orientation of the duckiebot throughout its trajectory. Using this sequence of orientations, you \n","can interpolate a path that the duckiebot has taken, and although it won't be done in this lab, fix the heading of the duckiebot so that it drives between the lanes of the road.\n","\n","###Steps to calculate orientation of robot\n","The overall steps you will follow are:\n","\n","- Pick some arbitrary distances from the duckiebot in the Z-axis of the road at which we would want to find the lane markings. For example, 50cm and 100 cm depth.\n","- Compute the v coordinate in the image (row within the image, which we'll call a scanline) which corresponds to the chosen depth or Z values to find the lanes. \n","- Find the left and right lane boundary's u coordinates in the image corresponding to the v values. Now we have image coordinates (u, v) of points on the left and right lanes.\n","- Convert the (u, v) coordinates of the lanes to camera coordinates: (X, Y, Z)\n","- Compute the line direction vector for the left lane and right lane respectively using the (X, Y, Z) points on those lanes.\n","- Average the two lines to find the optimal straight line in between the two lanes, and to remove noise.\n","- Find theta of the robot by computing the angle of the lane direction vector with respect to the camera optical axis.\n","\n","More details on the math behind these steps are below.\n","\n","###Detailed Description of Steps\n","\n","####Math Intuition behind the camera coordinate to image coordinate frame transform equation\n","\n","<!-- ![pinhole camera image](https://drive.google.com/uc?id=1uHU_NMLNZNOgVHhK8sUhjVDPE-36aUhz)  -->\n","\n","<figure>\n","<center>\n","<img width=520 height=450 src='https://drive.google.com/uc?id=1_IpRY2DjkjEnzvXTXlurNJa8VLt7p85K' />\n","<figcaption>Pinhole Camera</figcaption></center>\n","</figure>\n","\n","Image Link: https://drive.google.com/open?id=1_IpRY2DjkjEnzvXTXlurNJa8VLt7p85K\n","\n","Thus, given 3 variables, we can determine the 4th one using the above formula.\n","We will be using this formula to find the image coordinate v for the real word coordinate z and vice-versa.\n","\n","###Reference frames Description\n","\n","We will discuss the following reference frames in this project: \n","\n","- Road frame: reference frame with origin on the road directly below the duckiebot camera (between the front wheels). Z axis projects out in front of the duckiebot. X axis goes from left to right with respect to the duckiebot. And Y axis goes up and down. \n","\n","- IMPORTANT NOTE: The y coordinate of the robot that the students collected in part 1 of project 5, is really a z coordinate in the road frame, so keep that in mind.\n","\n","- Camera frame: reference frame with origin on the camera lens. Z axis projects out in front of the camera lens. X axis goes from left to right with respect to the camera lens. And Y axis goes up and down.\n","Note: Camera frame and road frame will have the same X axis coordinates. However, if the camera is tiled with a pitch and is not parallel to road, both the Z axis and Y axis coordinates will be different for road and camera reference frames.\n","\n","- Image frame: 2-D reference frame of the actual digital image. The origin is the top left of the image as shown below, with u going from left to right, and v going from up to down.\n","\n","<figure>\n","<center>\n","<img width=180 height=150 src='https://drive.google.com/uc?id=1oFqDBqSrl_6lbk6Yu3Kltfttmq-6VXTI' />\n","<figcaption></figcaption></center>\n","</figure>\n","\n","Image Link: https://drive.google.com/open?id=1oFqDBqSrl_6lbk6Yu3Kltfttmq-6VXTI\n","\n","###Math behind steps\n","\n","The objective of this assignment can be explained using following steps:\n","\n","<b>Step 1.</b> We pick some arbitrary distances from the duckiebot in the road frame at which we would want to find the lane markings e.g 50cm, 100cm etc away from the duckiebot. These values are stored in **Z_cm** variable.\n","\n","<b>Step 2.</b> Having picked some z distance in the road frame, we wonder where in the 2-D image will the distance of z cm lie. Here, we use the Pinhole camera equation to find v coordinate in the image given z. v value in the image frame will represent the height in pixels that corresponds to the point z in camera frame.\n","\n","The formula for v given z is below and is found in https://dellaert.github.io/20S-3630/Slides/L15_Pinhole_and_Stereo.pdf slide 17:\n","\n","<figure>\n","<center>\n","<img width=500 height=300 src='https://drive.google.com/uc?id=1rNkSiIKOhkeUjXZED7emVZAva2YvKX6t' />\n","<figcaption></figcaption></center>\n","</figure>\n","\n","Image link: https://drive.google.com/open?id=1rNkSiIKOhkeUjXZED7emVZAva2YvKX6t\n","\n","Note, that the camera is tilted at some angle (Camera Pitch) below the horizontal axis as shown in image below. We recorded this angle value in part 1. This means that a Z distance of 50 cm for example in the road frame will be slightly different in the camera frame. We have to transform Z from the road frame to the camera frame. You will need to find this conversion using trigonometry, and use the image below for guidance.\n","\n","The camera tilt with some pitch will also affect the Y coordinate of the road in the camera frame. If the camera was facing parallel to the road, all the road points would be a constant camera_height away from the camera in the Y axis. However since the camera has a pitch, the road Y coordinate in the camera frame will get smaller and smaller. Please use the image below for guidance in finding the Y coordinate of the road in the camera frame. After finding the Z in the camera frame of the road, use it to find the Y coordinate frame of the road (use trigonometry to find both).\n","\n","<figure>\n","<center>\n","<img width=900 height=300 src='https://drive.google.com/uc?id=1NfKRXWKAqOO4aGkJxccirYTRlJwJVylw' />\n","<figcaption></figcaption></center>\n","</figure>\n","\n","Image Link: https://drive.google.com/open?id=1NfKRXWKAqOO4aGkJxccirYTRlJwJVylw\n","\n","<b>Step 3.</b> The v value is a y-coordinate that represents an imaginary vertical scan line in the image, along which we will be finding lane pixels in the following steps. Since the height of the image = 480 pixels, v will lie between 0 and 479. \n","\n","Note that in an image, the origin is at the top-left and u increases from left to right and v increases from top to bottom, as shown in the image reference frame section. After successfully running 'compute_v_coordinate_of_scan_line_in_image' function, you can verify this property of the image by checking that v value will be larger for smaller z value and vice-versa i.e farther the z, closer will be the corresponding v to the origin on top-left of the image.\n","\n","<b>Step 4.</b> For a given v value, we now want to find the x-coordinates of the points where each of the left and right lanes intersects the imaginary scan line at height=v. Since the length of our images = 640 pixels, we store the 640 values at a given v in a 1D vector. We will then apply Image Processing techniques to this vector to find 2 lane pixels (one from left and right lanes each). Since the lane pixels are white and track is grey, lane pixels can be found by searching for highest intensity pixels.\n","\n","Note:  images can be converted from RGB to grayscale, where each pixel is represented by a value between 0-255, 0 being the darkenst intensity and 255 being the brightest.\n","\n","<b>Step 5.</b> Once our algorithm determines the left and right lane's x-coordinates at a scan line, we can repeat the same for multiple scan lines. As a result, we will have multiple pixels for the lane boundaries, as shown below.\n","\n","<figure>\n","<center>\n","<img width=500 height=300 src='https://drive.google.com/uc?id=1hbgWrM4pkrAg95_BRXxvBogofa2ObT4a' />\n","<figcaption></figcaption></center>\n","</figure>\n","\n","Image Link: https://drive.google.com/open?id=1hbgWrM4pkrAg95_BRXxvBogofa2ObT4a\n","\n","<b>Step 6.</b> Now, that we have the lane pixels in image, we can use 'compute_camera_coordinates_from_image_coordinates' function to find the camera coordinates (X,Y,Z) of lane pixels (u,v). This can be done using pinhole camera equation. \n","\n","Note, that this time we know the image coordinate and want to determine the camera coordinate using Pinhole camera equation.\n","\n","<b>Step 7.</b> We can proceed by fitting a line along the left and right lane's camera coordinates respectively. This will give us 2 lane vectors in the camera frame.\n","\n","<b>Step 8.</b> We want to determine the angle by which our robot deflected during its motion. Inorder to determine the angle of the detected lane vectors with respect to the optical axis, we take the mean of the 2 detected lane vectors to get one final lane vector. Then, we simply find the orientation of the robot using trigonometry. Use the image below for reference.\n","<figure>\n","<center>\n","<img width=560 height=500 src='https://drive.google.com/uc?id=1czqAxkBqO0f0l8N7dcGOUCq-4yIXxkNw' />\n","<figcaption></figcaption></center>\n","</figure>\n","\n","Image Link: https://drive.google.com/open?id=1czqAxkBqO0f0l8N7dcGOUCq-4yIXxkNw\n"," "]},{"cell_type":"markdown","metadata":{"id":"SstB60Vakehg","colab_type":"text"},"source":["##2. CODE [50 points]"]},{"cell_type":"code","metadata":{"id":"H3YYUlYGkd67","colab_type":"code","outputId":"a764bd4b-483b-42d9-b7b1-b2f2f6d96f2c","executionInfo":{"status":"ok","timestamp":1585158543665,"user_tz":240,"elapsed":3597,"user":{"displayName":"Fei Ding","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1zlJO_l7lSjgYADaSnUhsglZ0faTwTz7h2POUOQ=s64","userId":"00432297234436282683"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["!pip install gtsam"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gtsam in /usr/local/lib/python3.6/dist-packages (4.0.2)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gtsam) (1.18.2)\n","Requirement already satisfied: Cython>=0.25.2 in /usr/local/lib/python3.6/dist-packages (from gtsam) (0.29.15)\n","Requirement already satisfied: backports-abc>=0.5 in /usr/local/lib/python3.6/dist-packages (from gtsam) (0.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zvgC9SGzkeNj","colab_type":"code","colab":{}},"source":["import numpy as np\n","import cv2\n","import math\n","import unittest\n","import PIL\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import gtsam\n","import gtsam.utils.plot as gtsam_plot\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x9DnTjk0tPjA","colab_type":"text"},"source":["### The LaneFinder Class\n","This is the class where you will be implementing the main portion of the assignment.\n","\n","The functions you will be implementing code in are:\n","\n","- ```compute_orientation``` [8 points]\n","- ```compute_v_coordinate_of_scan_line_in_image``` [8 points]\n","- ```find_lane_boundaries_on_scan_line``` [10 points]\n","- ```compute_camera_coordinates_from_image_coordinates``` [8 points]\n","- ```compute_line_direction_from_points``` [5 points]\n","- ```compute_angle_of_lane_with_optical_axis``` [5 points]\n","\n","There are 6 corresponding unit tests for each of the functions."]},{"cell_type":"code","metadata":{"id":"nGrguyZeo2Pm","colab_type":"code","colab":{}},"source":["class LaneFinder:\n","  \"\"\"\n","  A class used to find the orientation of the robot with respect to a lane over time.\n","  \"\"\"\n","  def __init__(self, f, height, v0, u0, camera_pitch, Z_list, DEBUG=False):\n","    \"\"\"\n","    Create a LaneFinder object\n","    Parameters:\n","      - f: focal length of the camera\n","      - height: height of the camera from the ground\n","      - v0: half of the image height\n","      - u0: half of the image width\n","      - camera_pitch: angle of the camera\n","      - Z_list: The Z Values for both of the scan lines.\n","      - DEBUG: Set this to True for more detailed debug messages.\n","    \"\"\"\n","    self.f = f\n","    self.height = height\n","    self.v0 = v0\n","    self.u0 = u0\n","    self.camera_pitch = camera_pitch\n","    self.scan_lines = Z_list\n","    self.thetas = []\n","    self.DEBUG = DEBUG\n","\n","  def compute_orientation(self, image):\n","    \"\"\"\n","    This function computes the orientation of the robot with the respect to the \n","    vertical Z axis vector in the road frame, given an image with road lanes.\n","    The following steps are followed:\n","    - Compute v (row within the image) for both scan lines\n","    - Find lane boundaries (u) corresponding to both v values\n","    - Convert both (u, v) pairs to camera coordinates: (X, Y, Z)\n","    - Compute the line direction vector for each pair of (X, Y, Z) points.\n","    - Average the two lines to find the optimal straight line in\n","      between the two lanes.\n","    - Find theta of the robot by computing the angle of the optimal path with \n","      respect to the optical axis\n","\n","    You can expect around 5-10 degrees of error in the overall calculation of theta.\n","\n","    Params:\n","      -image: the image captured by the duckiebot on the road with lanes.\n","    Returns:\n","      -angle: the angle in radians of the orientation of the robot with \n","      respect to the vertical Z axis in the road frame.\n","    \"\"\"\n","    Z_in_camera_frame_list = []\n","    #########################################################################\n","    #STUDENT TODO: Implement this code snippet.\n","\n","    # Take list of Z values in the road frame, and modify them to find the Z \n","    # in the camera frame\n","\n","    # Z_in_camera_frame_list = list of Z values in the camera frame. Keep in mind \n","    # the Z_list in the world frame can be accessed as self.scan_lines.\n","    # Z_in_camera_frame_list should be a list data type\n","    #########################################################################\n","    \n","    Z_in_camera_frame_list = [Z_in_road_frame / math.cos(self.camera_pitch) for Z_in_road_frame in self.scan_lines]\n","    \n","\n","    #########################################################################\n","    #                             END OF YOUR CODE                          \n","    #########################################################################\n","\n","    # Compute the v coordinate in an image corresponding to a given depth in \n","    # camera frame. These v coordinates will give you a scan line in the image,\n","    # which is the row of pixels along the v coordinate\n","    v_list = []\n","    for Z in Z_in_camera_frame_list:\n","      v_list.append(self.compute_v_coordinate_of_scan_line_in_image(Z))\n","    if self.DEBUG:\n","      print(\"coordinate of scan lines in image are :\", v_list)\n","\n","    # Find the u values corresponding to the lanes boundaries\n","    # in the image for the computed v values\n","    u_list = []\n","    for v in v_list:\n","      u_list.append(self.find_lane_boundaries_on_scan_line(image, v))\n","    \n","    if self.DEBUG:\n","      print(\"Lane boundaries on scan lines are : \", u_list)\n","\n","    # Find the 3D coordinates w.r.t camera frame, corresponding to the u,v w, \n","    # coordinates of the image, where w = Z_in_camera_frame\n","    left_lane_points_in_camera_frame = []\n","    right_lane_points_in_camera_frame = []\n","    for i in range(len(v_list)):\n","      left_point = self.compute_camera_coordinates_from_image_coordinates(u_list[i][0], v_list[i], Z_in_camera_frame_list[i])\n","      left_lane_points_in_camera_frame.append(left_point)\n","      right_point = self.compute_camera_coordinates_from_image_coordinates(u_list[i][1], v_list[i], Z_in_camera_frame_list[i])\n","      right_lane_points_in_camera_frame.append(right_point)\n","    if self.DEBUG:\n","      print(\"Left points in camera frame:\", left_lane_points_in_camera_frame)\n","      print(\"Right points in camera frame:\", right_lane_points_in_camera_frame)\n","\n","    # Find the line (direction vector) corresponding to the left lane and right \n","    # lane respectively\n","    left_lane_direction_vector = self.compute_line_direction_from_points(left_lane_points_in_camera_frame)\n","    right_lane_direction_vector = self.compute_line_direction_from_points(right_lane_points_in_camera_frame)\n","    if self.DEBUG:\n","      print(\"Left line direction vector:\", left_lane_direction_vector)\n","      print(\"Right line direction vector:\", right_lane_direction_vector)\n","\n","    # Take the average of the two lines.\n","    optimal_path_vector = (left_lane_direction_vector+right_lane_direction_vector)/2 #U, V, W of the expected line\n","\n","    # Calculate the heading of the robot with respect to the \n","    # vertical Z axis vector in the road frame\n","    orientation_in_radians = self.compute_angle_of_lane_with_optical_axis(optimal_path_vector)\n","    if self.DEBUG:\n","      print(\"Result in degrees: \", math.degrees(orientation_in_radians))\n","    self.thetas.append(orientation_in_radians)\n","    \n","    return orientation_in_radians\n","\n","  def compute_v_coordinate_of_scan_line_in_image(self, Z):\n","    \"\"\"\n","    TODO:\n","    Compute the v coordinate in the image corresponding to a particular depth Z.\n","    Params:\n","      - Z: the selected depth that we are finding a corresponding v pixel row for.\n","    Returns:\n","      - v: the v coordinate of the scan line associated with depth Z\n","    \"\"\"\n","    #########################################################################\n","    # STUDENT TODO: Implement this code snippet.\n","\n","    # To calculate v, use the equation from L15_Pinhole_and_Stereo.pdf \n","    # https://dellaert.github.io/20S-3630/Slides/L15_Pinhole_and_Stereo.pdf\n","    # Slide 17.\n","    \n","    # However, Y != camera_height, because the camera is tilted down, so not \n","    # all road coordinates will be a constant height distance in the Y direction\n","    # from the camera.\n","    \n","    # Format of code:\n","    # First calculate Y for a given camera_pitch, Z, and height of the camera from\n","    # ground.\n","    # Then calculate v using the given Y, and return v.\n","    \n","    # All the pixels along this v coordinate, form a scan line corresponding to the\n","    # depth Z.\n","    #########################################################################\n","    \n","    # Calculate Y for a given camera_pitch, Z, and height of the camera from\n","    # ground.\n","    Y = self.height - math.sin(self.camera_pitch) * Z\n","    # Calculate v using the given Y\n","    v = self.v0 + self.f * Y / Z\n","    #########################################################################\n","    #                             END OF YOUR CODE                          \n","    #########################################################################\n","    return v\n","\n","  def find_lane_boundaries_on_scan_line(self, image, v):\n","    \"\"\"\n","    TODO:\n","    Compute the two u coordinates corresponding to the two lanes on the road\n","    in the scan line corresponding to v.\n","\n","    STUDENT TODO: \n","    Search through the intensities for the two lanes. In a grayscale image\n","    the higher the value of the pixels, the closer to white they are. Using this,\n","    determine the u values of the centers of the left and right lane boundaries.\n","    \n","    Some ideas for approaches include: using a convolutional filter (np.convolve),\n","    using a threshold, searching for the widest group of white pixels, etc.\n","    This will take some experimentation.\n","    \n","    Some tips:\n","    - Make sure you don't choose two pixels from the same lane boundary as your\n","      chosen u values.\n","    - Make sure u_left is the lesser value and u_right is greater.\n","    - Make sure you choose the u values at the middle of the lane so when you compute\n","      the line vector for the lane boundary, the points are consistently in the center\n","      of the boundary.\n","\n","    Params:\n","      -v: the v scan line coordinate\n","      -the image in which we will be looking for the lane in the scan line at row v\n","    Returns:\n","      -u_left: the u coordinate in the scan line of the left lane\n","      -u_right: the u coordinate in the scan line of the right lane\n","    \"\"\"\n","    u_left = 0\n","    u_right = 0\n","\n","    # Get the intensities corresponding to a scanline on v\n","    intensities = image[round(v)]\n","\n","    #########################################################################\n","    # STUDENT TODO:\n","    # Implement any operations that you want to perform on the raw intensities.\n","    #########################################################################\n","\n","    # apply gaussian filter\n","    filter_length = 15 # size of gaussian kernel\n","    sigma = 2 # standard deviation\n","    mid = int(filter_length / 2)\n","    gaussian_filter = [(1/(sigma*np.sqrt(2*np.pi)))*(1/(np.exp((i**2)/(2*sigma**2)))) for i in range(-mid,mid+1)]\n","    y = np.convolve(intensities, gaussian_filter, mode='same')\n","\n","    # apply max filter\n","    size = 15 # filter size\n","    y = [np.max(y[i:i+size]) for i in range(0, len(y) - size)]\n","    left_padding = int(size / 2)\n","    right_padding = size - left_padding\n","    y = np.array([y[0]] * left_padding + y + [y[-1]] * right_padding)\n","\n","    # find two peaks by soft thresholding\n","    tolerance = 10 # maximal change in adjacent pixel intensities\n","    stretch = 5 # number of pixels to suppress (set 0) out of range\n","    buffer = y.copy()\n","    mid = np.argmax(buffer)\n","    left = mid\n","    while abs(left - 1 >= 0 and buffer[left - 1] - buffer[left]) <= tolerance:\n","      left = left - 1\n","    right = mid\n","    while abs(right + 1 < len(buffer) and buffer[right + 1] - buffer[right]) <= tolerance:\n","      right = right + 1\n","    mid = int((left + right) / 2)\n","    u1 = mid\n","    # plt.scatter(mid, buffer[mid], color='k')\n","    buffer[max(0, left - stretch):min(len(intensities), right + stretch + 1)] = 0\n","    mid = np.argmax(buffer)\n","    left = mid\n","    while abs(left - 1 >= 0 and buffer[left - 1] - buffer[left]) <= tolerance:\n","      left = left - 1\n","    right = mid\n","    while abs(right + 1 < len(buffer) and buffer[right + 1] - buffer[right]) <= tolerance:\n","      right = right + 1\n","    mid = int((left + right) / 2)\n","    u2 = mid\n","    # plt.scatter(mid, buffer[mid], color='k')\n","\n","\n","    # x = np.arange(0, len(intensities))\n","    # plt.plot(x, intensities)\n","    # plt.plot(x, y)\n","    # plt.show()\n","\n","    #########################################################################\n","    #                             END OF YOUR CODE                          \n","    #########################################################################\n","\n","    # Plot the intensities. Feel free to change the variable if you want to visualize\n","    # your modified array of the intensities.\n","    if self.DEBUG:\n","      plt.plot(np.arange(len(image[0])), intensities)\n","      plt.show()\n","\n","    #########################################################################\n","    # STUDENT TODO: Implement this code snippet.\n","    #\n","    # After transforming the intensities, search through the array to determine\n","    # the center of the left and right lanee boundaries. Make sure you don't select\n","    # two pixels from the same lane boundary. A helpful function might be np.argsort\n","    #########################################################################\n","    \n","    u_left = min(u1, u2)\n","    u_right = max(u1, u2)\n","    # print(u_left, u_right)\n","    \n","    #########################################################################\n","    #                             END OF YOUR CODE                          \n","    #########################################################################\n","    return np.array([u_left, u_right])\n","\n","  def compute_camera_coordinates_from_image_coordinates(self, u, v, Z):\n","    \"\"\"\n","    Compute the camera coordinates X,Y,Z corresponding to the u,v,w camera\n","    coordinates, where w = Z.\n","\n","    Params:\n","      - u: the u coordinate of the image\n","      - v: the v coordinate of the image\n","      - Z: the w coordinate of the image = Z value in camera frame 3d space\n","    Returns:\n","      - np.array([X, Y, Z]): an np array of X,Y,Z of the camera coordinate\n","      corresponding to the u,v,w camera coordinates, where w = Z. \n","    \"\"\"\n","    X = 0\n","    Y = 0\n","    #########################################################################\n","    # STUDENT TODO: Implement this code snippet.\n","    #\n","    # Calculate Y using the same formula you used in \n","    # compute_v_coordinate_of_scan_line_in_image()\n","    # \n","    # Calculate X using the equation in L15_Pinhole_and_Stereo.pdf \n","    # https://dellaert.github.io/20S-3630/Slides/L15_Pinhole_and_Stereo.pdf\n","    # Slide 17.\n","    #########################################################################\n","\n","    X = (u - self.u0) / self.f * Z\n","    Y = self.height - math.sin(self.camera_pitch) * Z\n","\n","    #########################################################################\n","    #                             END OF YOUR CODE                          \n","    #########################################################################\n","    return np.array([X, Y, Z])\n","  \n","  def compute_line_direction_from_points(self, points):\n","    \"\"\"\n","    Computes the line direction vector corresponding to a given set of \n","    points in the camera frame. For now, we will assume we are only using\n","    2 points to form a line.\n","\n","    Params:\n","      - points: a list of numpy arrays. Each numpy array is a 3 element array of\n","        (X, Y, Z) coordinates of a point on the lane in the camera frame\n","    Returns:\n","      - line: a 3 element numpy array, which represents the direction vector\n","        of the lane boundary, calculated from the points that fall on the lane\n","        boundary.\n","    \"\"\"\n","    line = np.zeros(3,)\n","    #########################################################################\n","    # STUDENT TODO: Implement this code snippet.\n","\n","    # Compute the line direction vector corresponding to a two sets of \n","    # points in the camera frame. This should be 1 line of code and\n","    # should be saved in variable \"line\".\n","    #########################################################################\n","\n","    line = points[1] - points[0]\n","    \n","\n","    #########################################################################\n","    #                             END OF YOUR CODE                          \n","    #########################################################################\n","    return line\n","  \n","  def compute_angle_of_lane_with_optical_axis(self, lane_line):\n","    \"\"\"\n","    Compute the angle of the lane with respect to the optical axis.\n","    Params:\n","      - lane_line: a 3 dimensional numpy array, which represents the direction vector\n","        of the lane, calculated from the points on the lane\n","    Returns:\n","      - orientation: the orientation in radians of the robot with the respect to the \n","        vertical Z axis vector in the road frame    \n","    \"\"\"\n","    orientation = 0\n","    #########################################################################\n","    # STUDENT TODO: Implement this code snippet.\n","    #########################################################################\n","\n","    orientation = np.arctan(lane_line[0] / lane_line[2])\n","\n","    #########################################################################\n","    #                             END OF YOUR CODE                          \n","    #########################################################################\n","    return orientation"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vXw19UMTqlyv","colab_type":"code","outputId":"2cca694b-cda2-40ab-d196-326953956b65","executionInfo":{"status":"ok","timestamp":1585158560002,"user_tz":240,"elapsed":1508,"user":{"displayName":"Fei Ding","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1zlJO_l7lSjgYADaSnUhsglZ0faTwTz7h2POUOQ=s64","userId":"00432297234436282683"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#########################################################################\n","# STUDENT TODO: You will have to authenticate colab to access your Google\n","# drive files. Run the following line of code and follow the instructions.\n","#########################################################################\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VCL-A2ywuhdH","colab_type":"text"},"source":["### Running the LaneFinder on your captured images\n","In this section you will be filling in the initialization values for the LaneFinder. [3 points]"]},{"cell_type":"code","metadata":{"id":"Ua2BXgAYqn5J","colab_type":"code","outputId":"a22ea624-306d-418a-9b8c-9da3c0df6a0a","executionInfo":{"status":"ok","timestamp":1585158599940,"user_tz":240,"elapsed":997,"user":{"displayName":"Fei Ding","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1zlJO_l7lSjgYADaSnUhsglZ0faTwTz7h2POUOQ=s64","userId":"00432297234436282683"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#########################################################################\n","# STUDENT TODO: Enter your path to the captured images from Part 1. They \n","# should all be in a single folder in your google drive and they should follow\n","# the naming convention that was used when they were captured (frameX.png).\n","#########################################################################\n","image_path = '/content/drive/My Drive/CS 3630/Project5/saved_images/'\n","#########################################################################\n","#                             END OF YOUR CODE                          \n","#########################################################################\n","\n","count = 0\n","for f in os.listdir(image_path):\n","  if \"frame\" in f:\n","    count += 1\n","\n","\"\"\"\n","TODO:\n","Set the inputs to LaneFinder class.\n","\n","- Z_cm: list of depth values for scan lines. For now, just initialize list \n","  [50, 100]. These are in cm units. You might have to adjust these \n","  values if there is no lane on both sides in the image at this distance from the bot.\n","\n","- camera_pitch_cm: the camera pitch in degrees. We're assuming angle is positive \n","  as the camera is tilted down.\n","\n","- focal_length_in_pixels: focal length in unit pixels that we get from the\n","  camera matrix K that we collected from the duckiebot. Take the average of fx and\n","  fy from the camera matrix to compute this.\n","\n","- height_of_camera_cm: the height of the camera from the ground on the \n","  duckiebot. height should be measured to the center of the camera lens.\n","\n","- v0: v coordinate of the center coordinate of image. \n","  v0 = (the image height or number of pixels along v axis)/2.\n","  Alternatively you can use the v0 from the camera matrix but it should be very\n","  similar. V axis in an image goes from up to down.\n","\n","- u0: u coordinate of the center coordinate of image. \n","  u0 = (the image width or number of pixels along u axis)/2.\n","  Alternatively you can use the u0 from the camera matrix but it should be very\n","  similar. The u axis in image goes from left to right\n","\n","- DEBUG: set this flag to True if you would like more detailed debug messages.\n","\"\"\"\n","image_shape = (480, 640)\n","#########################################################################\n","# STUDENT TODO: Implement this code snippet.\n","# Set the inputs for the LaneFinder class.\n","#########################################################################\n","\n","Z_cm = [50, 100]\n","camera_pitch_cm = 16\n","focal_length_in_pixels = (307.737929460576 + 314.9827773443905) / 2\n","height_of_camera_cm = 9.8\n","v0 = 244.4605588877848\n","u0 = 329.6923679516850\n","DEBUG = False\n","\n","#########################################################################\n","#                             END OF YOUR CODE                          \n","#########################################################################\n","\n","# Create the LaneFinder object.\n","lane_finder = LaneFinder(focal_length_in_pixels, height_of_camera_cm, v0, u0, math.radians(camera_pitch_cm), Z_cm, DEBUG=DEBUG)\n","\n","# Loop through images in google drive, and calculate the orientation of the robot at each frame\n","for i in range(count):\n","  filename = \"frame\"+str(i)+\".png\"\n","  if not os.path.exists(os.path.join(image_path, filename)):\n","    continue\n","  print(\"Processing:\", filename)\n","  arr = np.asarray(PIL.Image.open(os.path.join(image_path, filename)).convert('L'))\n","  theta_radians = lane_finder.compute_orientation(arr)\n","  theta_degrees = math.degrees(theta_radians)\n","  print(\"Computed theta in radians:\", theta_radians)\n","  print(\"Computed theta in degrees:\", theta_degrees)\n","print(\"All computed thetas in radians:\", lane_finder.thetas)\n","print(\"All computed thetas in degrees:\", [math.degrees(theta) for theta in lane_finder.thetas])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Processing: frame0.png\n","Computed theta in radians: 0.02025553128480836\n","Computed theta in degrees: 1.1605564544147209\n","Processing: frame1.png\n","Computed theta in radians: 0.01865028288642539\n","Computed theta in degrees: 1.0685824961172417\n","Processing: frame2.png\n","Computed theta in radians: 0.015439505954828046\n","Computed theta in degrees: 0.8846185289787493\n","Processing: frame3.png\n","Computed theta in radians: 0.025070617059225205\n","Computed theta in degrees: 1.4364405472822876\n","Processing: frame4.png\n","Computed theta in radians: 0.050726019514733434\n","Computed theta in degrees: 2.906386829692478\n","Processing: frame5.png\n","Computed theta in radians: 0.05072601951473347\n","Computed theta in degrees: 2.90638682969248\n","Processing: frame6.png\n","Computed theta in radians: 0.06193126656346207\n","Computed theta in degrees: 3.5484001939860503\n","Processing: frame7.png\n","Computed theta in radians: 0.0715234928820913\n","Computed theta in degrees: 4.097994278177816\n","Processing: frame8.png\n","Computed theta in radians: 0.07950703103926447\n","Computed theta in degrees: 4.55541732016549\n","Processing: frame9.png\n","Computed theta in radians: 0.0619312665634621\n","Computed theta in degrees: 3.548400193986052\n","Processing: frame10.png\n","Computed theta in radians: 0.053928943273307606\n","Computed theta in degrees: 3.0899008431609567\n","Processing: frame11.png\n","Computed theta in radians: 0.049124162808080574\n","Computed theta in degrees: 2.8146072010165435\n","Processing: frame12.png\n","Computed theta in radians: 0.05713075986067568\n","Computed theta in degrees: 3.2733514203921277\n","Processing: frame13.png\n","Computed theta in radians: 0.06672891693849246\n","Computed theta in degrees: 3.8232853120546486\n","Processing: frame14.png\n","Computed theta in radians: 0.06193126656346207\n","Computed theta in degrees: 3.5484001939860503\n","Processing: frame15.png\n","Computed theta in radians: 0.057130759860675645\n","Computed theta in degrees: 3.2733514203921255\n","Processing: frame16.png\n","Computed theta in radians: 0.049124162808080504\n","Computed theta in degrees: 2.8146072010165395\n","Processing: frame17.png\n","Computed theta in radians: 0.03469707856277437\n","Computed theta in degrees: 1.9879961630808154\n","Processing: frame18.png\n","Computed theta in radians: 0.02186067528597771\n","Computed theta in degrees: 1.2525244311924668\n","Processing: frame19.png\n","Computed theta in radians: 0.02507061705922524\n","Computed theta in degrees: 1.4364405472822896\n","Processing: frame20.png\n","Computed theta in radians: 0.10656926748781462\n","Computed theta in degrees: 6.1059692528525185\n","All computed thetas in radians: [0.02025553128480836, 0.01865028288642539, 0.015439505954828046, 0.025070617059225205, 0.050726019514733434, 0.05072601951473347, 0.06193126656346207, 0.0715234928820913, 0.07950703103926447, 0.0619312665634621, 0.053928943273307606, 0.049124162808080574, 0.05713075986067568, 0.06672891693849246, 0.06193126656346207, 0.057130759860675645, 0.049124162808080504, 0.03469707856277437, 0.02186067528597771, 0.02507061705922524, 0.10656926748781462]\n","All computed thetas in degrees: [1.1605564544147209, 1.0685824961172417, 0.8846185289787493, 1.4364405472822876, 2.906386829692478, 2.90638682969248, 3.5484001939860503, 4.097994278177816, 4.55541732016549, 3.548400193986052, 3.0899008431609567, 2.8146072010165435, 3.2733514203921277, 3.8232853120546486, 3.5484001939860503, 3.2733514203921255, 2.8146072010165395, 1.9879961630808154, 1.2525244311924668, 1.4364405472822896, 6.1059692528525185]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M3Fh1fHurkOD","colab_type":"text"},"source":["### Plotting your results\n","\n","The below code will be used to plot your robot's movement trajectory, using the calculated theta values at each of the frames captured. The x, y position will be extrapolated naively using the following approach:\n","\n","- Calculate the total euclidean distance travelled\n","- At each frame, walk ```total_dist/N``` in the direction of $\\theta_i$ where N is the number of frames and $\\theta_i$ is the computed $\\theta$ at timestep i\n","\n","Fill in the ground truth values you collected during part 1 below. [3 points]"]},{"cell_type":"code","metadata":{"id":"Qp7Sppy7rHmp","colab_type":"code","outputId":"394fdd06-14d3-4eb7-9b53-17eb6c184487","executionInfo":{"status":"ok","timestamp":1585158648588,"user_tz":240,"elapsed":540,"user":{"displayName":"Fei Ding","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1zlJO_l7lSjgYADaSnUhsglZ0faTwTz7h2POUOQ=s64","userId":"00432297234436282683"}},"colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["#########################################################################\n","# STUDENT TODO: Enter your ground truth data from Part 1.\n","# - final_x: your change in x (in cm)\n","# - final_y: your change in y (in cm)\n","# - theta: your measured change in theta (radians)\n","# You might have to adjust the signs to make the image look correct.\n","# The resulting graph will show your robot's coordinate frame as it moves\n","# for the 20+ frames that you captured. It will also show the final pose that\n","# you measured in Part 1. The units in the resulting plot are in meters.\n","#########################################################################\n","final_x = -2.86\n","final_y = 107.3\n","theta = 0.03490658503988659\n","#########################################################################\n","#                             END OF YOUR CODE                          \n","#########################################################################\n","\n","total_dist = math.sqrt(final_x**2 + final_y**2)\n","thetas = lane_finder.thetas\n","origin = (0, 0, 0)\n","current_x = 0\n","current_y = 0\n","poses = []\n","dist_to_travel = (total_dist/len(thetas))\n","\n","# Intermediate X and Y values are extrapolated by equally dividing the distance\n","# traveled amongst each frame, and traveling that distance along the calculated\n","# thetas at each step.\n","for t in thetas:\n","  # Some sign manipulation to make the visualization.\n","  poses.append(gtsam.Pose2(current_x/100, current_y/100, t))\n","  current_x = current_x + dist_to_travel * math.sin(-t)\n","  current_y = current_y + dist_to_travel * math.cos(-t)\n","\n","\n","# Add ground truth pose to the image\n","poses.append(gtsam.Pose2(final_x/100, final_y/100, theta))    \n","\n","\n","fig = plt.figure(0)\n","for i in range(len(poses)):\n","    gtsam_plot.plot_pose2(0, poses[i])\n","\n","plt.axis('equal')\n","plt.show()\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"rWmTmlZOrN1e","colab_type":"code","colab":{}},"source":["# Run this to unmount your google drive folders.\n","drive.flush_and_unmount()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9UGzMRbwsVay","colab_type":"text"},"source":["### Unit Tests\n","\n","These unit tests will verify the basic functionality of all of the functions you will implement. Note, these are not exhaustive and will just test some basic cases."]},{"cell_type":"code","metadata":{"id":"T4ZDP6AVrP4D","colab_type":"code","outputId":"519f9ee7-a558-428e-e193-00484213b90c","executionInfo":{"status":"ok","timestamp":1585158650004,"user_tz":240,"elapsed":879,"user":{"displayName":"Fei Ding","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1zlJO_l7lSjgYADaSnUhsglZ0faTwTz7h2POUOQ=s64","userId":"00432297234436282683"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["import unittest\n","\n","class TestLaneFinder(unittest.TestCase):\n","\n","    def setUp(self):\n","      self.lane_finder = LaneFinder(310, 10, 240, 320, math.radians(30), [50, 100])\n","  \n","    def test_compute_orientation(self):\n","      \"\"\"\n","      Tests the compute_orientation function.\n","      Creates a dummy 300x300 image with parallel lines of white pixels for lane \n","      boundaries (only at the scan line rows).\n","      Note: This test will pass by default, this does not mean your implementation\n","      is correct. The function will return 0 by default, and this test expects 0.\n","      Make sure you test your code for robustness on your own as these tests are not exhaustive.\n","      \"\"\"\n","\n","      image = np.zeros((300, 300))\n","      self.lane_finder.f = 50\n","      self.lane_finder.camera_pitch = math.radians(0)\n","      self.lane_finder.v0 = 150\n","      self.lane_finder.u0 = 150\n","      image[155][50] = 255\n","      image[155][250] = 255\n","      image[160][100] = 255\n","      image[160][200] = 255\n","\n","      self.assertEqual(self.lane_finder.compute_orientation(image), 0)\n","      self.assertEqual(len(self.lane_finder.thetas), 1)\n","      \n","    def test_compute_v_coordinate_of_scan_line_in_image(self):\n","      \"\"\"\n","      Tests the compute_v_coordinate_of_scan_line_in_image function.\n","      Given the parameters used in the setUp function, and some custom parameters,\n","      verify the implementation of the function.\n","      \"\"\"\n","      \n","      self.assertAlmostEqual(147, self.lane_finder.compute_v_coordinate_of_scan_line_in_image(50))\n","      self.assertAlmostEqual(116, self.lane_finder.compute_v_coordinate_of_scan_line_in_image(100))\n","      self.lane_finder.f = 100\n","      self.lane_finder.height = 5\n","      self.lane_finder.camera_pitch = math.radians(45)\n","      self.assertAlmostEqual(240 + (5-math.sqrt(2)*50), self.lane_finder.compute_v_coordinate_of_scan_line_in_image(100))\n","\n","    def test_find_lane_boundaries_on_scan_line(self):\n","      \"\"\"\n","      Tests the find_lane_boundaries_on_scan_line function.\n","      Creates a dummy 3x150 image with two white pixels. Tests the implementation\n","      to make sure the peaks are found and both returned.\n","      \"\"\"\n","      v = 2\n","      image = np.zeros((3, 150))\n","      # Choose two peaks\n","      peaks = np.array([45, 123])\n","      \n","      image[2][peaks] = 255\n","\n","      pairs = np.array(self.lane_finder.find_lane_boundaries_on_scan_line(image, v))\n","      self.assertEqual(pairs.shape, (2,))\n","      self.assertEqual(np.sort(pairs)[0], np.sort(peaks)[0])\n","      self.assertEqual(np.sort(pairs)[1], np.sort(peaks)[1])\n","    \n","    def test_compute_camera_coordinates_from_image_coordinates(self):\n","      \"\"\"\n","      Tests the compute_camera_coordinates_from_image_coordinates_function.\n","      Uses two different configurations to test the conversion from 2D to 3D coordinates.\n","      \"\"\"\n","      self.lane_finder.height = 320\n","      self.lane_finder.camera_pitch = 0\n","      self.assertTrue(all(self.lane_finder.compute_camera_coordinates_from_image_coordinates(320, 320, 320) == np.array([0, 320, 320])))\n","      self.lane_finder.camera_pitch = math.radians(90)\n","      self.lane_finder.f = 320\n","      self.assertTrue(all(self.lane_finder.compute_camera_coordinates_from_image_coordinates(160, 320, 320) == np.array([-160, 0, 320])))\n","\n","    def test_compute_line_direction_from_points(self):\n","      \"\"\"\n","      Test the compute_line_direction_from_points function.\n","      Makes sure the line is computed correctly and both points fall on the line.\n","      \"\"\"\n","      P1 = np.array([1, 2, 3])\n","      P2 = np.array([4, 5, 6])\n","      line_direction = self.lane_finder.compute_line_direction_from_points(np.array([P1, P2]))\n","      self.assertEqual(np.sum(np.cross(line_direction, (P2-P1))), 0)\n","      self.assertTrue(all(np.abs(line_direction) == np.array([3, 3, 3])))\n","\n","    def test_compute_angle_of_lane_with_optical_axis(self):\n","      \"\"\"\n","      Test the compute_angle_of_lane_with_optical_axis function.\n","      Uses two simple angles to verify the implementation.\n","      \"\"\"\n","      angle = self.lane_finder.compute_angle_of_lane_with_optical_axis(np.array([1, 2, 1]))\n","      self.assertAlmostEqual(angle, math.radians(45))\n","      angle = self.lane_finder.compute_angle_of_lane_with_optical_axis(np.array([100, 5, 100 * math.sqrt(3)]))\n","      self.assertAlmostEqual(angle, math.radians(30))\n","      \n","if __name__ == '__main__':\n","  unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["......\n","----------------------------------------------------------------------\n","Ran 6 tests in 0.019s\n","\n","OK\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"fxRE0WgUz0Vq","colab_type":"text"},"source":["## 3. Reflection [50 points]\n","\n","Answer the questions in the proj5_part2_report_template.pptx. \n","You can find the pptx file in the files tab on Canvas.  \n","Save the file as a PDF and rename it to LASTNAME1_LASTNAME2_LASTNAME3_LASTNAME4_reflection2.pdf\n"]},{"cell_type":"markdown","metadata":{"id":"pBj9VvFLx4RC","colab_type":"text"},"source":["### Rubric\n","- 50 pts: Successfully completed the code.\n","- 50 pts: reflection writeup"]},{"cell_type":"markdown","metadata":{"id":"m_6EhCqH0t4O","colab_type":"text"},"source":["### Submission Details\n","#### Deliverables\n","\n","You will have these three files to submit for parts 1 and 2. They should be uploaded as separate files and not in a zip.\n","- saved_images.zip - A zip of your 20 images captured from running `move_forward_and_capture_images.py`\n","- LASTNAME1_LASTNAME2_LASTNAME3_LASTNAME4_reflection1.pdf: The reflection slides converted to PDF form. \n","- LASTNAME1_LASTNAME2_LASTNAME3_LASTNAME4_reflection2.pdf: The reflection slides converted to PDF form. \n","- Project5.py (Created from converting .ipynb to .py)\n","    1. To submit this code, you will need to download this .ipynb file as a .py file (File -> Download as .py).\n","    2. You will also need to include a screenshot of your unit test results in the reflection PowerPoint (a slide has been marked for that).\n","\n","\n","\n","\n","Only one person per 4-person group should upload the submission. "]},{"cell_type":"code","metadata":{"id":"DIW7YCPyzAf8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}